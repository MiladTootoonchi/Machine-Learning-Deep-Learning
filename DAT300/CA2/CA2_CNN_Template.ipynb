{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compulsory Assignment 2: Convolutional neural networks\n",
    "\n",
    "Please fill out the group name, number, members and optionally the name below.\n",
    "\n",
    "**Group number**: 26  \n",
    "**Group member 1**: Milad Tootoonchi  \n",
    "**Group member 2**: Sania Minaipour  \n",
    "**Group member 3**: Makka Dulgaeva  \n",
    "\n",
    "\n",
    "# Assignment Submission\n",
    "To complete this assignment answer the relevant questions in this notebook and write the code required to implement the relevant models. The assignment is submitted by handing in this notebook as an .ipynb file and as a .pdf file. \n",
    "\n",
    "# Introduction \n",
    "In this assignment, you will build a Convolutional Neural Network (CNN) to classify images of natural scenes from around the world.\n",
    "Dataset: Intel-image-classification\n",
    "https://www.kaggle.com/datasets/puneet6060/intel-image-classification\n",
    "\n",
    "This Data contains around 25k images of size 150x150 distributed under 6 categories.\n",
    "{'buildings' -> 0,\n",
    "'forest' -> 1,\n",
    "'glacier' -> 2,\n",
    "'mountain' -> 3,\n",
    "'sea' -> 4,\n",
    "'street' -> 5 }\n",
    "\n",
    "#### In CA2, we use only 3 classes \"buildings\", \"forest\", \"sea\".\n",
    "\n",
    "This data was initially published on https://datahack.analyticsvidhya.com by Intel to host a Image classification Challenge.\n",
    "## Landscape Pictures\n",
    "\n",
    "Example image:\n",
    "\n",
    "\n",
    "<center><img src=\"20497.jpg\" width=\"500\" height=\"400\"></center>\n",
    "\n",
    "\n",
    "## Assignment structure\n",
    "\n",
    "1. Part 0: Setup & Data\n",
    "2. Part 1: Baseline CNN (Clean Data)\n",
    "3. Part 2: Choose Your Robustness Challenges\n",
    "4. Part 3: Results & Comparison\n",
    "\n",
    "```\n",
    "\n",
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to add or remove libraries as you want\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow.keras as ks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Setup & Data, CNN for Landscape Picture dataset \n",
    "### NOTE FOR STUDENTS:\n",
    "\n",
    "Do not forget to change the path of root_dir below so it points to the Intel folder which contains the dataset inside your CA2 directory.\n",
    "### Example:\n",
    "\n",
    "Windows: r\"C:\\Users\\yourname\\...\\CA2\\Intel\"\n",
    "\n",
    "Mac/Linux: \"/home/yourname/CA2/Intel\"\n",
    " \n",
    "## Loading DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `class_names` passed did not match the names of the subdirectories of the target directory. Expected: ['seg_train'] (or a subset of it), but received: class_names=['buildings', 'forest', 'sea']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutilities\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_intel_dataset\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m data = \u001b[43mload_intel_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/home/milad/repositories/Machine-Learning-Deep-Learning/DAT300/CA2/Intel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mselected_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbuildings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforest\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msea\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m train_ds, val_ds, test_ds = data[\u001b[33m\"\u001b[39m\u001b[33mtrain_ds\u001b[39m\u001b[33m\"\u001b[39m], data[\u001b[33m\"\u001b[39m\u001b[33mval_ds\u001b[39m\u001b[33m\"\u001b[39m], data[\u001b[33m\"\u001b[39m\u001b[33mtest_ds\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     19\u001b[39m class_names = data[\u001b[33m\"\u001b[39m\u001b[33mclass_names\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Machine-Learning-Deep-Learning/DAT300/CA2/utilities.py:40\u001b[39m, in \u001b[36mload_intel_dataset\u001b[39m\u001b[34m(root_dir, img_size, val_size, batch_size, random_seed, verbose, selected_classes)\u001b[39m\n\u001b[32m     37\u001b[39m test_dir  = os.path.join(root_dir, \u001b[33m\"\u001b[39m\u001b[33mseg_test\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Training dataset with validation split\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m train_ds = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minferred\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mint\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mselected_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# None = all\u001b[39;49;00m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     51\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m val_ds = tf.keras.utils.image_dataset_from_directory(\n\u001b[32m     54\u001b[39m     train_dir,\n\u001b[32m     55\u001b[39m     labels=\u001b[33m\"\u001b[39m\u001b[33minferred\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     63\u001b[39m     subset=\u001b[33m\"\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     64\u001b[39m )\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Test dataset (no split, just full test set)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Machine-Learning-Deep-Learning/.venv/lib/python3.12/site-packages/keras/src/utils/image_dataset_utils.py:232\u001b[39m, in \u001b[36mimage_dataset_from_directory\u001b[39m\u001b[34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    231\u001b[39m     seed = np.random.randint(\u001b[32m1e6\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m image_paths, labels, class_names = \u001b[43mdataset_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mformats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mALLOWLIST_FORMATS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label_mode == \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(class_names) != \u001b[32m2\u001b[39m:\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    245\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mWhen passing `label_mode=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`, there must be exactly 2 \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mclass_names. Received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    247\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repositories/Machine-Learning-Deep-Learning/.venv/lib/python3.12/site-packages/keras/src/utils/dataset_utils.py:538\u001b[39m, in \u001b[36mindex_directory\u001b[39m\u001b[34m(directory, labels, formats, class_names, shuffle, seed, follow_links, verbose)\u001b[39m\n\u001b[32m    536\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m class_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    537\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mset\u001b[39m(class_names).issubset(\u001b[38;5;28mset\u001b[39m(subdirs)):\n\u001b[32m--> \u001b[39m\u001b[32m538\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    539\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mThe `class_names` passed did not match the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    540\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mnames of the subdirectories of the target directory. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    541\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubdirs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (or a subset of it), \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    542\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbut received: class_names=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    543\u001b[39m             )\n\u001b[32m    544\u001b[39m         subdirs = class_names  \u001b[38;5;66;03m# Keep provided order.\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    546\u001b[39m     \u001b[38;5;66;03m# In the explicit/no-label cases, index from the parent directory down.\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: The `class_names` passed did not match the names of the subdirectories of the target directory. Expected: ['seg_train'] (or a subset of it), but received: class_names=['buildings', 'forest', 'sea']"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import utilities\n",
    "\n",
    "# Force reload the updated utilities.py\n",
    "importlib.reload(utilities)\n",
    "\n",
    "from utilities import load_intel_dataset\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "data = load_intel_dataset(\n",
    "    root_dir=r\"...\",\n",
    "    img_size=(224, 224),\n",
    "    selected_classes=[\"buildings\", \"forest\", \"sea\"],  #  only 3 classes\n",
    "    verbose=1\n",
    "    \n",
    ")\n",
    "\n",
    "X_train, y_train = data[\"X_train\"], data[\"y_train\"]\n",
    "X_val,   y_val   = data[\"X_val\"],   data[\"y_val\"]\n",
    "X_test,  y_test  = data[\"X_test\"],  data[\"y_test\"]\n",
    "class_names      = data[\"class_names\"]\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Val:\",   X_val.shape,   y_val.shape)\n",
    "print(\"Test:\",  X_test.shape,  y_test.shape)\n",
    "\n",
    "# Show number of images per class\n",
    "def count_per_class(y, split_name):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"\\n{split_name} set class distribution:\")\n",
    "    for cls, cnt in zip(unique, counts):\n",
    "        print(f\"  {class_names[cls]}: {cnt}\")\n",
    "\n",
    "count_per_class(y_train, \"Train\")\n",
    "count_per_class(y_val,   \"Val\")\n",
    "count_per_class(y_test,  \"Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Normalizing input between [0,1]\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m X_train = X_train.astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m) / \u001b[32m255.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mX_train\u001b[49m.size \u001b[38;5;28;01melse\u001b[39;00m X_train\n\u001b[32m      3\u001b[39m X_val   = X_val.astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)   / \u001b[32m255.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X_val.size \u001b[38;5;28;01melse\u001b[39;00m X_val\n\u001b[32m      4\u001b[39m X_test  = X_test.astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m)  / \u001b[32m255.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X_test.size \u001b[38;5;28;01melse\u001b[39;00m X_test\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Normalizing input between [0,1]\n",
    "X_train = X_train.astype(\"float32\") / 255.0 if X_train.size else X_train\n",
    "X_val   = X_val.astype(\"float32\")   / 255.0 if X_val.size else X_val\n",
    "X_test  = X_test.astype(\"float32\")  / 255.0 if X_test.size else X_test\n",
    "\n",
    "# Converting targets from numbers to categorical format\n",
    "if y_train is not None and y_train.size:\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    y_train = ks.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "if y_val is not None and y_val.size:\n",
    "    y_val = ks.utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "if y_test is not None and y_test.size:\n",
    "    y_test = ks.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\",   X_val.shape)\n",
    "print(\"X_test shape:\",  X_test.shape)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build a CNN network with the LeNet5 architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implement LeNet5 architecture for Landscape Pictures (RGB): \n",
    "\n",
    "--------------------------\n",
    "The LeNet architecture takes a 32×32×C image as input, where C is the number of color channels. You may use resize_dataset() and f1_score() from utilities.py¶\n",
    "\n",
    "Input & resizing: Resize all images to 32×32 and use C = 3 channels (RGB).\n",
    "If you choose a different input size, update the intermediate shapes accordingly, but keep the LeNet-5 pattern (Conv → Pool → Conv → Pool → FC → FC → FC).\n",
    "\n",
    "**Layer 1 - Convolution (5x5):** The output shape should be 28x28x6. **Activation:** ReLU. \n",
    "\n",
    "**MaxPooling:** The output shape should be 14x14x6.\n",
    "\n",
    "**Layer 2 - Convolution (5x5):** The output shape should be 10x10x16. **Activation:** ReLU. \n",
    "\n",
    "**MaxPooling:** The output shape should be 5x5x16.\n",
    "\n",
    "**Flatten:** Flatten the output shape of the final pooling layer such that it's 1D instead of 3D.  You may need to use tf.reshape.\n",
    "\n",
    "**Layer 3 - Fully Connected:** This should have 120 outputs. **Activation:** ReLU.\n",
    "\n",
    "**Layer 4 - Fully Connected:** This should have 84 outputs. **Activation:** ReLU.\n",
    "\n",
    "**Layer 5 - Fully Connected (output):** **`num_classes`**. **Activation:** softmax\n",
    "\n",
    "--------------------------\n",
    "\n",
    "\n",
    "##### Compile the network with the\n",
    "* `tf.keras.losses.CategoricalCrossentropy` loss function\n",
    "* the `adam` optimizer \n",
    "* with the `accuracy` metric and (your own implementation of the) F1-score metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1.2 Train network\n",
    "\n",
    "Train the network with a \n",
    "* batch size of 64 samples\n",
    "* for 20 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1.3 \n",
    "Experiment with different architectures of your choice. Vary the number of filters, try different kernel sizes, add more layers, dropout, early stopping, and modify the fully connected layers. Report the best performance you achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2 Evaluaiton\n",
    "### Task 1.2.1 Plot training history \n",
    "- Plot the training/validation accuracy and loss curves (plot_training_history() is in utilities.py).\n",
    "- Report the final validation accuracy (f1_score() is in utilities.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.2 Evaluate on the test dataset\n",
    "- Report test accuracy (and F1 score (f1_score() is in utilities.py))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2.3 Create a confusion matrix for both training and testing data\n",
    "- Visualize confusion matrices.\n",
    "- Do the test data and train data predict the same items wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Robustness (choose two or more), You may use add_gaussian_noise() and add_motion_blur() from utilities.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1 Data Augmentation (training-time)\n",
    "- Implement an augmentation pipeline.\n",
    "- Train a model with augmentation and compare against the baseline from Part 1.\n",
    "\n",
    "### Task 2.2 Noise Robustness (test-time corruptions)\n",
    "- Create corrupted versions of the test images and evaluate the baseline model:\n",
    "  - Gaussian noise\n",
    "  - Motion blur\n",
    "- Report accuracy on the clean test set vs. each corrupted test set.\n",
    "\n",
    "### Task 2.3  Discussion (no coding)\n",
    "- Which noise types affect the model most?\n",
    "- What techniques could improve robustness (data augmentation, adversarial training, denoising pre-processing, larger models)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Results & Comparison\n",
    "- Summarize results (table/plot):\n",
    "  - Baseline (clean) vs. Augmented (if attempted)\n",
    "  - Clean vs. each corrupted test set (Task 2.2)\n",
    "- Brief discussion:\n",
    "  - Which corruptions hurt most, and why?\n",
    "  - Did augmentation help? Which transforms mattered?\n",
    "  - What would you try next (e.g., stronger augmentation, adversarial training, denoising pre-processing, larger models, early stopping, ensembling)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
